<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ErrorRadar: Benchmarking Complex Mathematical Reasoning of Multimodal Large Language Models Via Error Detection
  </title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><img src="static/images/radar.png"
                style="width:1.5em;vertical-align: middle" alt="Logo" />ErrorRadar: Benchmarking Complex Mathematical
              Reasoning of
              Multimodal Large Language Models Via Error Detection</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Yibo Yan</a><sup>1,2,3</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Shen Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Jiahao Huo</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Hang Li</a><sup>4</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Boyan Li</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Jiamin Su</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Xiong Gao</a><sup>2</sup>,
              </span>
              <br>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Yi-Fan Zhang</a><sup>1,5</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Tianlong Xu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Zhendong Chu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Aoxiao Zhong</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="PERSONAL LINK" target="_blank">Kun Wang</a><sup>1,5</sup>,
              </span>
              <br>
              <span class="author-block">
                <a href="https://www.hkust-gz.edu.cn/people/hui-xiong/" target="_blank">Hui Xiong</a><sup>2,3</sup>,
              </span>
              <span class="author-block">
                <a href="https://cs.uic.edu/profiles/philip-yu/" target="_blank">Philip S. Yu</a><sup>6</sup>,
              </span>
              <span class="author-block">
                <a href="https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/HU-Xuming/xuminghu"
                  target="_blank">Xuming Hu</a><sup>2,3,</sup><img src="static\images\email.png" alt="Vector Icon"
                  style="width: 16px; height: 16px; transform: translateY(-10px); margin-left: 2px;">,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/site/qingsongwen8/" target="_blank">Qingsong Wen</a><sup>1,</sup><img
                  src="static\images\email.png" alt="Vector Icon"
                  style="width: 16px; height: 16px; transform: translateY(-10px); margin-left: 2px;">
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <sup>1</sup>Squirrel Ai Learning, <sup>2</sup>HKUST(GZ), <sup>3</sup>HKUST, <sup>4</sup>MSU,
                <sup>5</sup>UCAS, <sup>6</sup>University of Illinois at Chicago
                <br><strong style="color: #0001A1;"><img src="static\images\email.png" alt="Vector Icon"
                    style="width: 16px; height: 20px; transform: translateY(-3px); margin-left: 2px;"> Corresponding
                  Authors</strong>
                <br><strong style="color: #C5272D; font-size: 25px;">Reasoning and Planning for LLMs Workshop @ICLR
                  2025</strong>
              </span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2410.04509" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://huggingface.co/datasets/ErrorRadar/ErrorRadar"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <p style="font-size:18px">ðŸ¤—</p>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>

                <!-- Supplementary PDF link
                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                <!-- Github link -->
                <!-- <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          Your video here -->
  <!-- <source src="static/videos/banner_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat
          pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              As the field of Multimodal Large Language Models (MLLMs) continues to evolve, their potential to
              revolutionize artificial intelligence is particularly promising, especially in addressing mathematical
              reasoning tasks.
              Current
              mathematical benchmarks predominantly focus on evaluating MLLMs' problem-solving ability, yet there is a
              crucial gap in
              addressing more complex scenarios such as error detection, for enhancing reasoning capability in
              complicated settings.
              To fill this gap, <span style="font-weight: bold; color: #2F2D54;">we formally formulate the new
                task: multimodal error detection, and introduce ErrorRadar, the first benchmark designed to assess
                MLLMs'
                capabilities in such a task</span>. ErrorRadar evaluates two
              sub-tasks: <span style="font-style: italic; color: #2F2D54;">error step identification</span> and <span
                style="font-style: italic; color: #2F2D54;">error categorization</span>, providing a comprehensive
              framework for evaluating MLLMs' complex
              mathematical
              reasoning ability. It consists of 2,500 high-quality multimodal K-12 mathematical problems, collected from
              real-world
              student interactions in an educational organization, with rigorous annotation and rich metadata such as
              problem type and
              error category. Through extensive experiments, we evaluated both open-source and closed-source
              representative MLLMs,
              benchmarking their performance against educational expert evaluators. Results indicate significant
              challenges still
              remain, as GPT-4o with best performance is still around 10% behind human evaluation.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <section class="section">
    <div class="container" style="margin-bottom: 2vh;">
      <!-- contribution and comparison -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Contributions</h2>
          <div class="content has-text-justified">
            <p>
              Our contributions can be summarized as follows:
            </p>
            <ul>
              <li>We take the <strong>first step to formulate the multimodal error detection task</strong>, and
                introduce a multimodal benchmark
                termed ErrorRadar for evaluation. This benchmark serves as a standard operator for assessing the complex
                mathematical
                reasoning capabilities of the latest MLLMs.
              </li>
              <li>We meticulously curate an extensive dataset comprising approximately 2,500 high-quality instances with
                <strong>rigorous
                  annotation and rich metadata derived from real user interactions</strong> in an educational
                organization. To the
                best of our
                knowledge, this is the first attempt to use real-world student problem-solving data to evaluate MLLMs,
                providing a
                protocol for future research on MLLMs' complex mathematical reasoning.
              </li>
              <li>Our <strong>comprehensive experimental evaluation of more than 20 MLLMs</strong>, both proprietary and
                open-source,
                highlight the
                substantial room for improvement (i.e., 7%-15% in performance) in the complex mathematical reasoning
                capabilities, underscoring the necessity for further research.
              </li>
            </ul>
            <p>
              Comparison of research scope between previous work and our proposed ErrorRadar benchmark on mathematical
              reasoning tasks.
            </p>
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/comparison.png" alt="SeePhys" width="40%" />
          </h2>
        </div>
      </div>
      <!--/ contribution and comparison -->
    </div>
  </section>

  <section class="section">
    <div class="container" style="margin-bottom: 2vh;">
      <!-- dataset details -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Dataset Details</h2>
          <div class="content has-text-justified">
            Key statistics of dataset
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/statistics.png" alt="SeePhys" width="25%" />
          </h2>
          <div class="content has-text-justified">
            Roadmap of dataset collection, annotation, and consistent update
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/dataset_roadmap.png" alt="SeePhys" width="55%" />
          </h2>
          <div class="content has-text-justified">
            Dataset distribution with respect to problem type and error category
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/category_flow.png" alt="SeePhys" width="55%" />
          </h2>
        </div>
      </div>
      <!--/ dataset details -->
    </div>
  </section>

  <section class="section">
    <div class="container" style="margin-bottom: 2vh;">
      <!-- experiment analysis -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Experimental Analysis</h2>
          <div class="content has-text-justified">
            Error category performance of top 10 MLLMs for F1, recall, and precision, respectively
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/model_performance_charts_layout_top10.png" alt="SeePhys" width="80%" />
          </h2>
          <div class="content has-text-justified">
            The radar charts of error category performance for the top eight MLLMs (each dimension indicates an error
            category)
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/radar_main.png" alt="SeePhys" width="80%" />
          </h2>
          <div class="content has-text-justified">
            Error step performance of top 10 MLLMs
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/step_performance_chart_top10.png" alt="SeePhys" width="55%" />
          </h2>
          <div class="content has-text-justified">
            The proportion of CAL predictions of respective closed-source and open-source MLLMs with top-5 CAL
            recall
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/CAL_bias_bar.png" alt="SeePhys" width="80%" />
          </h2>
          <div class="content has-text-justified">
            The error category distribution of misjudged VIS cases of GPT-4o
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/gpt4o_bad_case_distribution.jpg" alt="SeePhys" width="80%" />
          </h2>
          <div class="content has-text-justified">
            The error category distribution of misjudged VIS cases of CogVLM2-LLaMA3
          </div>
          <h2 class="title is-2 mathvista">
            <img src="static/images/llama.jpg" alt="SeePhys" width="80%" />
          </h2>
        </div>
      </div>
      <!--/ experiment analysis -->
    </div>
  </section>


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/task definition.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              First example of our annotated multimodal mathematical reasoning dataset ErrorRadar.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/task definition1.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Second example of our annotated multimodal mathematical reasoning dataset ErrorRadar.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/task definition2.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Third example of our annotated multimodal mathematical reasoning dataset ErrorRadar.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/task definition3.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Fourth example of our annotated multimodal mathematical reasoning dataset ErrorRadar.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/task definition4.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Fifth example of our annotated multimodal mathematical reasoning dataset ErrorRadar.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/task definition5.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Sixth example of our annotated multimodal mathematical reasoning dataset ErrorRadar.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->



  <!-- Paper poster -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">ICLR'25 Workshop Poster</h2>

        <iframe src="static/pdfs/ErrorRadar_Poster_ICLR25.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section>
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{yan2024errorradar,
      title={Errorradar: Benchmarking complex mathematical reasoning of multimodal large language models via error detection},
      author={Yan, Yibo and Wang, Shen and Huo, Jiahao and Li, Hang and Li, Boyan and Su, Jiamin and Gao, Xiong and Zhang,
      Yi-Fan and Xu, Tianlong and Chu, Zhendong and Zhong, Aoxiao and Wang, Kun and Xiong, Hui and Yu, Philip S. and Hu, Xuming and Wen, Qingsong},
      journal={arXiv preprint arXiv:2410.04509},
      year={2024}
      }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>